import csv
import logging
import math
import pickle
import sys
from collections import Counter
from itertools import combinations
from itertools import groupby
import matplotlib.pyplot as plt
import click
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(stream=sys.stdout, format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',
                    level=logging.INFO)


def extract_mapping_data(sam_file, NLR_annotation):
    """
    The function takes a SAM file as an input and generates a dictionary of all the reads that have been mapped to a
    given refernce sequence in the SAM file as list.

    :param NLR_annotation:
    :param sam_file: reads mapped to contigs generated by assembly of reads
    :return: dictionary: {contig:[all mapped reads]}
    """
    contig_read_dictionary = {}
    logging.info("extracting infromation from SAM file...")
    with open(sam_file) as file:
        for line in file:
            # extract all reference sequence names from SAM file and add to dictionary with an empty list
            if line.startswith("@SQ"):
                seq_name = line.split("\t")[1][3:]
                contig_read_dictionary[seq_name] = []

            # skip the header added by samtools
            elif line.startswith("@PG"):
                continue

            # read line of SAM file and extract reference sequence and query sequence names then append query sequence
            # to a list in the dictionary using the reference sequence as a key
            else:
                read_info = line.split("\t")
                query_name = read_info[0]
                reference_name = read_info[2]
                # if a sequence is unmapped to a reference move onto the next read
                if reference_name == "*":
                    continue
                else:
                    contig_read_dictionary[reference_name].append(query_name)

    nlr_contigs = []
    with open(NLR_annotation) as annotations:
        for line in annotations:
            nlr_contigs.append(line.split("\t")[0])

    nlr_read_dictionary = {nlr: contig_read_dictionary[nlr] for nlr in nlr_contigs}

    return nlr_read_dictionary


def convert_reads_to_rgb(contig_read_dictionary, index):
    """
    The function takes a dictionary of contigs each with a list of reads mapped to that contig and converts the read
    names to a list of rgb values based on an index file. The list RGB values is then converted to a string of
    hexidecimal values that can later be analysed to compare the similarity of contigs.

    :param contig_read_dictionary: dictionary of reads mapped to each contig generated by extracting_mapping_data()
    :param index: csv file where each read has been assigned a colour based its adapter sequence
    :return: contig_hex_dicitonary: {contig: string of hexidecimal values assinged for each read}
    """
    logging.info("extracting infromation from index file...")
    with open(index, mode='r') as inp:
        index_reader = csv.reader(inp)
        ID_colour_dict = {rows[0]: rows[1] for rows in index_reader}

    logging.info("converting Seq IDs to RGB values...")
    contig_rgb = {contig: tuple(map(lambda x: ID_colour_dict[x], contig_read_dictionary[contig])) for contig in
                  contig_read_dictionary}
    return contig_rgb


def plot_cosine_similarity(contig_rgb_dictionary, threshold):
    logging.info("converting rgb values to hexidecimal...")
    contig_hex_dictionary = {
        contig: list(map(lambda x: '#%02x%02x%02x' % tuple(map(int, x.split(","))), contig_rgb_dictionary[contig])) for
        contig in contig_rgb_dictionary}

    logging.info("converting hexidecimal to strings...")
    contig_adapter_profiles = [" ".join(contig_hex_dictionary[contig]) for contig in
                               contig_hex_dictionary][:300]

    logging.info("calculating cosine similarity...")
    count_array = CountVectorizer()
    profile_count_array = count_array.fit_transform(contig_adapter_profiles)
    cosine_array = cosine_similarity(profile_count_array)

    logging.info("plotting cosine similarity matrix...")
    plt.figure(figsize=(100, 100))
    cosine_plot = sns.heatmap(cosine_array, vmin=0, vmax=1, mask=cosine_array < threshold)
    cosine_plot.set_facecolor("black")
    fig = cosine_plot.get_figure()
    fig.savefig(f"cosine_plot_{threshold*100}.png", bbox_inches='tight')


def calculate_cosine_similarity(contig_rgb_dictionary, threshold):
    """
    The function takes a dicitonary of contigs each with a string of hexidecimal values that represent all reads mapped
    to the contig. The cosine similarity of the hexidecimal string of all contigs are compared in a pairwise manner.
    Contigs with a cosine similarity above a given threshold (0.95) are grouped together into sets. Duplicate sets are
    removed and the non-duplicate list of group contig lists is saved as pickle.

    :param threshold:
    :param contig_rgb_dictionary:
    :return: pickle file:
    """

    def counter_cosine_similarity(c1, c2):
        terms = set(c1).union(c2)
        dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)
        magA = math.sqrt(sum(c1.get(k, 0) ** 2 for k in terms))
        magB = math.sqrt(sum(c2.get(k, 0) ** 2 for k in terms))

        if magA == 0 or magB == 0:
            return 0

        else:
            return dotprod / (magA * magB)

    rgb_count = {contig: Counter(contig_rgb_dictionary[contig]) for contig in contig_rgb_dictionary}

    matched_contigs = {val: [val] for val in rgb_count}

    logging.info('calculating cosine similarity of contigs and grouping...')
    combos = combinations(rgb_count, 2)
    for t1, t2 in combos:
        cosine = counter_cosine_similarity(rgb_count[t1], rgb_count[t2])
        if cosine > threshold:
            matched_contigs[t1].append(t2)
            matched_contigs[t2].append(t1)

    logging.info('removing duplicate contig groups...')
    matched_contig_groups = [sorted(contig_list) for contig_list in matched_contigs.values()]
    non_duplicate_contig_groups = list(
        matched_contig_groups for matched_contig_groups, _ in groupby(matched_contig_groups))

    logging.info('writing data to pickle...')
    with open(f'grouped_contigs_{threshold*100}.pkl', 'wb') as f:
        pickle.dump(non_duplicate_contig_groups, f)


@click.command()
@click.option('-i', '--samfile', type=str, required=True, help="SAM file")
@click.option('-n', '--nlr', type=str, required=True, help="NLR annotator file")
@click.option('-x', '--index', type=str, required=True, help="Index file generated with colour mapper")
@click.option('-p', "--plot", type=bool, required=False, default=False, help="plot cosine similarity matrix")
@click.option('-t', '--threshold', type=float, required=False, default=0.8, help="cosine similarity threshold for grouping/plotting")
def calculate_similarity(samfile, nlr, index, plot, threshold):
    nlr_contig_reads = extract_mapping_data(samfile, nlr)
    contig_rgb = convert_reads_to_rgb(nlr_contig_reads, index)

    if plot:
        plot_cosine_similarity(contig_rgb, threshold)

    else:
        calculate_cosine_similarity(contig_rgb, threshold)
