import csv
import logging
import pickle
import sys

from itertools import permutations
from collections import Counter

import click
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(stream=sys.stdout, format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',
                    level=logging.INFO)


def extract_mapping_data(sam_file, NLR_annotation):
    """
    Loads a SAM file and generates a dictionary of all the reads that have been mapped to a refernce sequence in the
    SAM file as a list of reads. The dictionary is then reduced to contain only contigs that have been annotated as
    NLRs using NLR annotator

    :param NLR_annotation: NLR annotations for the orignal assembly generated with NLR annotator
    :param sam_file: reads mapped to contigs generated by assembly of reads
    :return: dictionary: {contig:[all mapped reads]}
    """
    contig_read_dictionary = {}
    logging.info("extracting reads from SAM file...")
    with open(sam_file) as file:
        for line in file:
            # extract all reference sequence names from SAM file and add to dictionary with an empty list
            if line.startswith("@SQ"):
                seq_name = line.split("\t")[1][3:]
                contig_read_dictionary[seq_name] = []

            # skip the header added by samtools
            elif line.startswith("@PG") or line.startswith("@HD"):
                continue

            # read line of SAM file and extract reference sequence and query sequence names then append query sequence
            # to a list in the dictionary using the reference sequence as a key
            else:
                read_info = line.split("\t")
                query_name = read_info[0]
                reference_name = read_info[2]
                # if a sequence is unmapped to a reference move onto the next read
                if reference_name == "*":
                    continue
                else:
                    contig_read_dictionary[reference_name].append(query_name)

    logging.info("extracting NLR annotaion data...")
    nlr_contigs = []

    with open(NLR_annotation) as annotations:
        for line in annotations:
            line_data = line.split("\t")
            nlr_contigs.append(line_data[0])

    nlr_read_dictionary = {nlr: contig_read_dictionary[nlr] for nlr in nlr_contigs}

    return nlr_read_dictionary


def convert_reads_to_hexidecimal(contig_read_dictionary, index):
    """
    The function takes a dictionary of contigs each with a list of reads mapped to that contig and converts the read
    names to a list of rgb values based on an index file. The list RGB values is then converted to a list of
    hexidecimal values that can later be analysed to compare the similarity of contigs.

    :param contig_read_dictionary: dictionary of reads mapped to each contig generated by extracting_mapping_data()
    :param index: csv file where each read has been assigned a colour based its adapter sequence
    :return: contig_hex_dicitonary: {contig: [hexidecimal values assinged for each read]}
    """
    logging.info("extracting information from index file...")
    with open(index, mode='r') as inp:
        index_reader = csv.reader(inp)
        ID_colour_dict = {rows[0]: rows[1] for rows in index_reader}

    logging.info("converting Seq IDs to RGB values...")
    contig_rgb = {contig: tuple(map(lambda x: ID_colour_dict[x], contig_read_dictionary[contig])) for contig in
                  contig_read_dictionary}

    logging.info("converting rgb values to hexidecimal...")
    contig_hex_dictionary = {
        contig: list(map(lambda x: '#%02x%02x%02x' % tuple(map(int, x.split(","))), contig_rgb[contig])) for
        contig in contig_rgb}

    return contig_hex_dictionary


def generate_cosine_matrix(contig_hex_dictionary):
    """
    Generates a text string for each contig using the hexidecimal profiles for each contig and then calculates the
    cosine similarity of all contigs in the dictionary. This is peformed in a pairwise manner and creates a matrix of all
    values.

    :param contig_hex_dictionary:
    :return: a 2D array of all cosine similarity values
    """
    logging.info("converting hexidecimal to strings...")
    contig_adapter_profiles = [" ".join(contig_hex_dictionary[contig]) for contig in
                               contig_hex_dictionary]

    logging.info("calculating cosine similarity...")
    count_array = CountVectorizer()
    profile_count_array = count_array.fit_transform(contig_adapter_profiles)
    cosine_array = cosine_similarity(profile_count_array)

    return cosine_array


def group_contigs(contig_hex, cosine_array, threshold):
    """
    generates a list of lists of all contigs that share a cosine similarity above the given threshold. The list is
    generated by grouping all contigs in a given row of the cosine matrix together. Each row in the matrix is assigned a
    number between 0 and n (max length of the matrix) as are the list of contigs from the dictionary used to generate the
    cosine matrix. Therefore, the two contigs compared at a given position in the matrix can be identified.

    EXAMPLE:

    contig dict:
    {0 : contig_1, 1 : contig_2, 2 : contig_3}

    cosine matrix:
    1.0 0.5 0.7
    0.5 1.0 0.8
    0.7 0.8 1.0

    @ threshold 0.7
    row 0: [0,2]
    row 1: [1,2]
    row 2: [0,1,2]

    convert positions to contig ids:
    row 0: [contig_1, contig_3]
    row 1: [contig_2, contig_3]
    row 2: [contig_1, contig_2, contig_3]

    The list of list is then filtered to remove a list that is a subset of another list. The count of each contig after
    this step in the list of lists should be 1. If this is not the case any list containing a contig that occurs more than
    once is removed from the list of list. These groups of contigs are often incorrect, massive and unhelpful. Any contig
    not found in the list of lists after this is added back to the list of lists as a list of itself. This ensures minimal
    data is lost during the filter process. Often complete NLRs are high promiscuous and have a high similairty to a range
    of partial and complete NLR contigs, thus the impact of this step is likely to be minimal. This list of lists is then
    returned as the output of the function

    :param contig_hex: the dictionary used to generate the cosine similarity matrix
    :param cosine_array: a matrix of the cosine similarity values generated by generate_cosine_matrix
    :param threshold: a float between 0 and 1.0
    :return: a list of Lists of contigs grouped together above the given threshold.
    """

    def flatten(array):
        # Converts a list of lists into a list
        return [item for sublist in array for item in sublist]

    def filter_by_cosine(array, dictionary, filter_threshold):
        """
        A number between 0 and n is assigned to each value in the array. The array is then iterated through to find all
        values above the given threshold. When a value is found its assigned number is used to look up the name of the
        contig in the dictionary provided. This leads to the generation of a list of all contigs above the threshold in
        the list (row of the cosine matrix).


        :param array: a list of floats between 0 and 1 (from cosine matrix, see above)
        :param dictionary: dictionary with all contigs numbered from 0 to n (see above)
        :param filter_threshold: float between 0 and 1.0
        :return: a list of all contigs in the array (row of the cosine matrix) above the given threshold
        """
        valid_contigs = []
        for n, cosine in enumerate(array):
            if cosine > filter_threshold:
                valid_contigs.append(dictionary[n])

        return sorted(valid_contigs)

    normalised_keys = {n: k for n, k in enumerate(list(contig_hex.keys()))}

    array_dict = {normalised_keys[n]: array for n, array in enumerate(cosine_array)}

    logging.info("grouping contig using cosine similarity matrix...")
    grouped_contigs = [filter_by_cosine(v, normalised_keys, threshold) for k, v in array_dict.items()]

    logging.info("removing subsets...")
    combos = permutations(grouped_contigs, 2)
    sub_groups = [g1 for g1, g2 in combos if set(g1).issubset(set(g2)) and g1 != g2]
    non_duplicate_group = [val.split() for val in
                           list(set([" ".join(val) for val in grouped_contigs if val not in sub_groups]))]

    logging.info("removing promiscuous contig groupings...")
    bad_contigs = [k for k, v in Counter(flatten(non_duplicate_group)).items() if v > 1]

    for bc in bad_contigs:
        non_duplicate_group = [group for group in non_duplicate_group if bc not in group]

    logging.info("re-adding removed contigs...")
    for val in list(contig_hex.keys()):
        if val not in flatten(non_duplicate_group):
            non_duplicate_group.append([val])

    return non_duplicate_group


def find_optimal_grouping(cosine_threshold_dictionary):
    """
    Generates a bar chart that shows the number of lists with 2 or more elements in the list of lists of contigs at
    a range of cosine similarity thresholds. The key for the list with the greatest number of list with two or more
    elements is then returned. This allows for the cosine threshold with the greatest number of combined partial NLRs to
    be identified and selected for further analysis. In theory, more complete NLRs can be assembled from this list with
    the greatest number of elements greater than 2.

    :param cosine_threshold_dictionary: a dictionary containing the list of lists of grouped contigs at varying cosine
            thresholds
    :return: The key for list of lists in the dictionary with most number of lists with 2 or more elements
    """

    logging.info("Plotting of number of groups at cosine thresholds...")
    n_grouped_contigs = {str(k): len([contig for contig in v if len(contig) > 1]) for k, v in
                         cosine_threshold_dictionary.items()}
    x = n_grouped_contigs.keys()
    y = list(n_grouped_contigs.values())

    col = []
    optimal_threshold = max(y)
    for val in y:
        if val == optimal_threshold:
            col.append('red')
        else:
            col.append('blue')

    plt.bar(*zip(*n_grouped_contigs.items()), color=col)
    plt.xlabel('Cosine Similarity Threshold')
    plt.ylabel('# Grouped Contigs')

    for i in range(len(x)):
        plt.text(i, y[i] + 2.5, y[i], ha='center')

    plt.savefig('cosine_threshold.png', dpi=300)

    logging.info("barchart was saved as cosine_threshold.png")

    logging.info("Optimal cosine threshold identified...")

    return max(n_grouped_contigs, key=n_grouped_contigs.get)


def pickle_data(contig_grouping):
    """
    Saves the optimal list of lists to a pickle file for further analysis

    :param contig_grouping: The list of lists of grouped contigs at the optimal threshold
    :return: None
    """
    logging.info('saving raw contig groups to pickle...')
    with open("raw_cosine_grouping.pkl", 'wb') as file:
        pickle.dump(contig_grouping, file)


@click.command()
@click.option('-i', '--samfile', type=str, required=True, help="SAM file")
@click.option('-n', '--nlr', type=str, required=True, help="NLR annotator file")
@click.option('-x', '--index', type=str, required=True, help="Index file generated with colour mapper")
def calculate_similarity(samfile, nlr, index):
    nlr_contig_reads = extract_mapping_data(samfile, nlr)
    contig_hex = convert_reads_to_hexidecimal(nlr_contig_reads, index)
    cosine_matrix = generate_cosine_matrix(contig_hex)

    threshold_dictionary = {threshold: group_contigs(contig_hex, cosine_matrix, threshold) for threshold in
                            [0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1]}

    optimal_threshold = find_optimal_grouping(threshold_dictionary)

    best_contig_grouping = threshold_dictionary[float(optimal_threshold)]

    pickle_data(best_contig_grouping)
